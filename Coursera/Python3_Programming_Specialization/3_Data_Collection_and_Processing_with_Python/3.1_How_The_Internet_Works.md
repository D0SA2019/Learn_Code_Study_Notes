# Data Collection and Processing with Python
*Coursera | Python 3 Programming Specialization | Course 3*

## Week 3 : Internet APIs
### 3.1. How The Internet Works

There’s an amazing variety of data out there on the Internet. We are all familiar with using a web browser to access it. We can also write computer programs that access data. Rather just showing it directly to people, computer programs can process the data in useful ways. They can also act on a much larger scale, processing more data from more sources.

In this chapter, you will learn how to use the python requests module to request data in python programs. We will also take a look behind the scenes to give you a better sense of what’s really going on when you request data over the Internet, either with a browser or from a Python program.


The Internet is a transport mechanism that lets any connected device communicate with any other connected device. Behind the scenes:

* Each device has a globally distinct IP address, which is a 32 bit number. Usually an IP address is represented as a sequence of four decimal numbers, each number in the range (0, 255). For example, when I checked the IP address for my laptop just now, it was 141.211.203.248. Any IP address beginning with 141.211 is for a device at the University of Michigan. When I take my laptop home and connect to a network there, my laptop gets a different IP address that it uses there.
* Data is chopped up into reasonable sized packets (up to 65,535 bytes, but usually much smaller).
* Each data packet has a header that includes the destination IP address.
* Each packet is routed independently, getting passed on from one computing device to another until it reaches its destination. The computing devices that do that packet forwarding are called routers. Each router keeps an address table that says, when it gets a packet for some destination address, which of its neighbors should it pass the packet on to. The routers are constantly talking to each other passing information about how they should update their routing tables. The system was designed to be resistant to any local damage. If some of the routers stop working, the rest of the routers talk to each other and start routing packets around in a different way so that packets still reach their intended destination if there is some path to get there. It is this technical capability that has spawned metaphoric quotes like this one from John Gilmore: “The Net interprets censorship as damage and routes around it.”
* At the destination, the packets are reassembled into the original data message.


![](https://raw.githubusercontent.com/hevalhazalkurt/Learn_Code_Study_Notes/master/Coursera/Python3_Programming_Specialization/3_Data_Collection_and_Processing_with_Python/images/routers.png)

#### Anatomy of URLs

A URL is used by a browser or other program to specify what server to connect to and what page to ask for. Like other things that will be interpreted by computer programs, URLs have a very specific formal structure. If you put a colon in the wrong place, the URL won’t work correctly. The overall structure of a URL is:

`<scheme>://<host>:<port>/<path>`


Usually, the *scheme* will be http or https. The s in https stands for “secure”. When you use https, all of the communication between the two devices is encrypted. Any devices that intercepts some of the packets along the way will be unable to decrypt the contents and figure out what the data was.

Other schemes that you will sometimes see include ftp (for file transfer) and mailto (for email addresses).

The *host* will usually be a domain name, like si.umich.edu or github.com or google.com. When the URL specifies a domain name, the first thing the computer program does is look up the domain name to find the 32-bit IP address. For example, right now the IP adddress for github.com is 192.30.252.130. This could change if, for example, github moved its servers to a different location or contracted with a different Internet provider. Lookups use something called the Domain Name System, or DNS for short. Changes to the mapping from domain names to IP addresses can take a little while to propagate: if github.com announces a new IP address associated with its domain, it might take up to 24 hours for some computers to start translating github.com to the new IP address.

Alternatively, the host can be an IP address directly. This is less common, because IP addresses are harder to remember and because a URL containing a domain name will continue to work even if the remote server keeps its domain name but moves to a different IP address.

The *:port* is optional. If it is omitted, the default port number is 80. The port number is used on the receiving end to decide which computer program should get the data that has been received. We probably will not encounter any URLs that include the : and a port number in this course.

The */path* is also optional. It specifies something about which page, or more generally which contents, are being requested.


For example, consider the url https://github.com/presnick/runestone:

* https:// says to use the secure http protocol
* github.com says to connect to the server at github.com, which currently maps to the IP address 192.30.252.130. The connection will be made on the default port, which is 443 for https.
* /presnick/runestone says to ask the remote server for the page presnick/runestone. It is up to the remote server to decide how to map that to the contents of a file it has access to, or to some content that it generates on the fly.

The url http://blueserver.com/path?k=val is another example that we can consider. The path here a bit different from https://github.com/presnick/runestone because it includes what are called “query parameters”, the information after the `?`.

![](https://fopp.umsi.education/runestone/static/fopp/_images/internet_requests.png)


#### The HTTP protocol

A protocol specifies the order in which parties will speak and the format of what they say and the content of appropriate responses.

HTTP is the protocol that specifies how web browsers or other programs communicate with web servers. One version of the formal specification, before it was later split into multiple documents, was IETF [RFC 2616](https://www.ietf.org/rfc/rfc2616.txt). It is 176 pages long! Fortunately, the basics are pretty easy to understand.

* **Step 1: the client makes a request to the server.**
	- If the request only involves fetching data, the client sends a message of the form `GET <path>`, where <path> is the path part of the URL
	- If the request involves sending some data (e.g., a file upload, or some authentication information), the message starts with `POST`
	- **In either case, the client sends some HTTP headers. These include:**
		* The type of client program. This allows the server to send back different things to small mobile devices than desktop browsers (a “responsive” website)
		* Any cookies that the server previously asked the client to hold onto. This allows the server to continue previous interactions, rather than treating every request as stand-alone. It also allows ad networks to place personalized ads.
	- After the HTTP headers, for a POST type communication, there is some data (the body of the request).

![](https://fopp.umsi.education/runestone/static/fopp/_images/argumentstoserver.png)

* **Step 2: the server responds to the client.**
	- **The server first sends back some HTTP headers. These include:**
		* a response code indicating whether the server thinks it has fulfilled the request or not.
		* a description of the type of content it is sending back (e.g., text/html when it is sending html-formatted text).
		* any cookies it would like the client to hold onto and send back the next time it communicates with the server.
	- After the headers come the contents. This is the stuff that you would see if you ask to “View Source” in a browser.

![](https://fopp.umsi.education/runestone/static/fopp/_images/serverresponse.png)

------
